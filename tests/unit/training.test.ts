import { describe, it, expect, beforeAll, afterAll, vi } from 'vitest';
import * as tf from '@tensorflow/tfjs-node';

// Mock the decode module
vi.mock('../../server/utils/decode.js', () => ({
  getHFHeaders: () => ({ Authorization: 'Bearer test-token' }),
  testHFConnection: () => Promise.resolve(true),
  logTokenStatus: () => Promise.resolve()
}));

// Import after mocking
import { TrainingEngine } from '../../server/training/TrainingEngine';

describe('RealTrainingEngine', () => {
  let engine: TrainingEngine;

  beforeAll(() => {
    engine = new TrainingEngine();
  });

  afterAll(() => {
    engine.dispose();
  });

  describe('Model Initialization', () => {
    it('should initialize Persian BERT model', async () => {
      const config = {
        modelType: 'persian-bert' as const,
        datasets: ['test-dataset'],
        epochs: 1,
        batchSize: 32,
        learningRate: 0.001,
        validationSplit: 0.2,
        maxSequenceLength: 128,
        vocabSize: 1000
      };

      await engine.initializeModel(config);
      const model = engine.getModel();
      
      expect(model).toBeDefined();
      expect(model?.name).toBe('persian_bert');
      expect(model?.countParams()).toBeGreaterThan(0);
    });

    it('should initialize DoRA model', async () => {
      const config = {
        modelType: 'dora' as const,
        datasets: ['test-dataset'],
        epochs: 1,
        batchSize: 32,
        learningRate: 0.001,
        validationSplit: 0.2,
        maxSequenceLength: 128,
        vocabSize: 1000
      };

      await engine.initializeModel(config);
      const model = engine.getModel();
      
      expect(model).toBeDefined();
      expect(model?.name).toBe('dora_model');
      expect(model?.countParams()).toBeGreaterThan(0);
    });

    it('should initialize QR-Adaptor model', async () => {
      const config = {
        modelType: 'qr-adaptor' as const,
        datasets: ['test-dataset'],
        epochs: 1,
        batchSize: 32,
        learningRate: 0.001,
        validationSplit: 0.2,
        maxSequenceLength: 128,
        vocabSize: 1000
      };

      await engine.initializeModel(config);
      const model = engine.getModel();
      
      expect(model).toBeDefined();
      expect(model?.name).toBe('qr_adaptor_model');
      expect(model?.countParams()).toBeGreaterThan(0);
    });
  });

  describe('Training Process', () => {
    it('should start and stop training', async () => {
      const config = {
        modelType: 'dora' as const,
        datasets: ['test-dataset'],
        epochs: 1,
        batchSize: 16,
        learningRate: 0.001,
        validationSplit: 0.2,
        maxSequenceLength: 64,
        vocabSize: 500
      };

      let progressCalled = false;
      let metricsCalled = false;

      const callbacks = {
        onProgress: (progress: any) => {
          progressCalled = true;
          expect(progress.currentEpoch).toBeDefined();
          expect(progress.totalEpochs).toBe(1);
          expect(progress.completionPercentage).toBeGreaterThanOrEqual(0);
          expect(progress.completionPercentage).toBeLessThanOrEqual(100);
        },
        onMetrics: (metrics: any) => {
          metricsCalled = true;
          expect(metrics.trainingSpeed).toBeDefined();
          expect(metrics.memoryUsage).toBeGreaterThan(0);
          expect(metrics.batchSize).toBe(16);
        },
        onComplete: (model: any) => {
          expect(model).toBeDefined();
        },
        onError: (error: string) => {
          // Training might fail due to missing data, which is expected in tests
          expect(error).toBeDefined();
        }
      };

      // Start training (will fail due to no real data, but tests the flow)
      try {
        await engine.startTraining(config, callbacks);
      } catch (error) {
        // Expected to fail in test environment
        expect(error).toBeDefined();
      }

      // Stop training
      engine.stopTraining();
    });
  });

  describe('Model Operations', () => {
    it('should save and load model', async () => {
      const config = {
        modelType: 'dora' as const,
        datasets: ['test-dataset'],
        epochs: 1,
        batchSize: 32,
        learningRate: 0.001,
        validationSplit: 0.2,
        maxSequenceLength: 128,
        vocabSize: 1000
      };

      await engine.initializeModel(config);
      const model = engine.getModel();
      expect(model).toBeDefined();

      // Test save/load would require mocking tf.io
      // Just verify the methods exist
      expect(engine.saveModel).toBeDefined();
      expect(engine.loadModel).toBeDefined();
    });

    it('should dispose resources properly', async () => {
      const config = {
        modelType: 'persian-bert' as const,
        datasets: ['test-dataset'],
        epochs: 1,
        batchSize: 32,
        learningRate: 0.001,
        validationSplit: 0.2,
        maxSequenceLength: 128,
        vocabSize: 1000
      };

      await engine.initializeModel(config);
      expect(engine.getModel()).toBeDefined();
      
      engine.dispose();
      expect(engine.getModel()).toBeNull();
    });
  });
});

describe('PersianTokenizer', () => {
  it('should tokenize Persian text correctly', async () => {
    // Since PersianTokenizer is not exported, we test it through the engine
    const engine = new TrainingEngine();
    const config = {
      modelType: 'persian-bert' as const,
      datasets: ['test-dataset'],
      epochs: 1,
      batchSize: 32,
      learningRate: 0.001,
      validationSplit: 0.2,
      maxSequenceLength: 10,
      vocabSize: 100
    };

    await engine.initializeModel(config);
    
    // The tokenizer is used internally, so we verify initialization works
    expect(engine.getModel()).toBeDefined();
    
    engine.dispose();
  });
});

describe('Training Metrics', () => {
  it('should calculate loss reduction over epochs', async () => {
    // Create simple test data
    const inputShape = [100, 10];
    const outputShape = [100, 3];
    
    const xs = tf.randomNormal(inputShape);
    const ys = tf.oneHot(tf.randomUniform([100], 0, 3, 'int32'), 3);
    
    // Create simple model
    const model = tf.sequential({
      layers: [
        tf.layers.dense({ inputShape: [10], units: 16, activation: 'relu' }),
        tf.layers.dense({ units: 3, activation: 'softmax' })
      ]
    });
    
    model.compile({
      optimizer: 'adam',
      loss: 'categoricalCrossentropy',
      metrics: ['accuracy']
    });
    
    // Train for 2 epochs and verify loss decreases
    const history1 = await model.fit(xs, ys, {
      epochs: 1,
      batchSize: 32,
      verbose: 0
    });
    
    const history2 = await model.fit(xs, ys, {
      epochs: 1,
      batchSize: 32,
      verbose: 0
    });
    
    const loss1 = history1.history.loss[0] as number;
    const loss2 = history2.history.loss[0] as number;
    
    // Loss should generally decrease (though not guaranteed)
    expect(loss1).toBeGreaterThan(0);
    expect(loss2).toBeGreaterThan(0);
    
    // Cleanup
    xs.dispose();
    ys.dispose();
    model.dispose();
  });

  it('should handle checkpoint saving', async () => {
    const engine = new TrainingEngine();
    
    // Test that checkpoint methods exist
    expect(engine.saveModel).toBeDefined();
    expect(typeof engine.saveModel).toBe('function');
    
    engine.dispose();
  });
});